{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "from torch.utils.data import Dataset\n",
    "from datasets import MyDataset\n",
    "import numpy as np\n",
    "\n",
    "## Batch Sizes\n",
    "train_batch_size = 256\n",
    "val_batch_size = train_batch_size\n",
    "\n",
    "## Train-Val Split\n",
    "train_kwargs = {\n",
    "    'root':'data/',\n",
    "    'train':True,\n",
    "    'download':True,\n",
    "    'transform':transforms.Compose([transforms.ToTensor()]),\n",
    "}\n",
    "val_kwargs = {\n",
    "    'root':'data/',\n",
    "    'train':False,\n",
    "    'download':True,\n",
    "    'transform':transforms.Compose([transforms.ToTensor()]),\n",
    "}\n",
    "dataset_name = 'CIFAR10'\n",
    "dataset_class = getattr(datasets, dataset_name)\n",
    "train_dataset_mnist = MyDataset(dataset_class(**train_kwargs).data, dataset_class(**train_kwargs).targets, uses_da=True)\n",
    "val_dataset_mnist = MyDataset(dataset_class(**val_kwargs).data, dataset_class(**val_kwargs).targets)\n",
    "val_dataset_mnist.set_norm_values(*train_dataset_mnist.get_norm_values())\n",
    "\n",
    "## DataLoaders\n",
    "train_loader_mnist = torch.utils.data.DataLoader(train_dataset_mnist, batch_size=train_batch_size, shuffle=True)\n",
    "val_loader_mnist = torch.utils.data.DataLoader(val_dataset_mnist, batch_size=val_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# print example\n",
    "for k,(data, target) in enumerate(train_loader_mnist):\n",
    "#for k,(data, target) in enumerate(val_loader_mnist):\n",
    "    ind = 37\n",
    "    data = data#['x']\n",
    "    target = target#['y']\n",
    "    print('data', data.shape, data.device ,data.dtype, data.min(), data.max())\n",
    "    print('target', target.shape, target.device, target.dtype, target.min(), target.max())\n",
    "    img = data[ind].permute(1,2,0).numpy()\n",
    "    plt.imshow(img)\n",
    "    plt.title(f'target: {target[ind]}')\n",
    "    break\n",
    "    \n",
    "print(len(train_loader_mnist))\n",
    "print(len(val_loader_mnist))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from flamingChoripan.myUtils.lists import get_list_of_dics, merge_lists, Iter, decompose_dic_Iter\n",
    "from baseline_models import MLPClassifier, CNN2DClassifier\n",
    "\n",
    "mdl_params = {\n",
    "    #'mdl_class':MLPClassifier,\n",
    "    'mdl_class':CNN2DClassifier,\n",
    "    'mdl_kwargs':{\n",
    "        'dropout':0.5,\n",
    "        #'dropout':0.0,\n",
    "        'cnn_features':[16, 32, 64],\n",
    "        #'cnn_features':[16, 32],\n",
    "        'uses_mlp_classifier':True,\n",
    "        #'uses_mlp_classifier':False,\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from flamingChoripan.myUtils.prints import print_bar\n",
    "import torch.optim as optims\n",
    "from flamingChoripan.tinyFlame import _C\n",
    "from flamingChoripan.tinyFlame.handler import ModelsTrainHandler\n",
    "from flamingChoripan.tinyFlame.train_handlers import NewTrainHandler\n",
    "from flamingChoripan.tinyFlame.losses import NewLossCrit, crossentropy\n",
    "from flamingChoripan.tinyFlame.optimizers import NewOptimizer\n",
    "from flamingChoripan.tinyFlame.metrics import NewMetricCrit, onehot_accuracy, dummy_accuracy\n",
    "\n",
    "LOAD = 0\n",
    "\n",
    "#### LOSS\n",
    "loss_kwargs = {\n",
    "    'model_output_is_with_softmax':False,\n",
    "    'target_is_onehot':False,\n",
    "    'target_is_onehot':False,\n",
    "    #'pred_dict_key':'x',\n",
    "    #'target_dict_key':'y',\n",
    "}\n",
    "loss_crit1 = NewLossCrit(crossentropy, loss_kwargs)\n",
    "loss_crit2 = NewLossCrit(crossentropy, loss_kwargs)\n",
    "\n",
    "#### METRICS\n",
    "metric_crits = [\n",
    "    NewMetricCrit('accuracy', onehot_accuracy, loss_kwargs),\n",
    "    NewMetricCrit('dummy-accuracy', dummy_accuracy, loss_kwargs),\n",
    "]\n",
    "\n",
    "#### OPTIMIZERS\n",
    "optimizer_kwargs = {\n",
    "    'opt_kwargs':{\n",
    "        'lr':1e-3,\n",
    "    },\n",
    "    'decay_kwargs':{\n",
    "        'lr':0.9,\n",
    "    }\n",
    "}\n",
    "optimizer1 = NewOptimizer(optims.Adam, **optimizer_kwargs)\n",
    "optimizer2 = NewOptimizer(optims.Adam, **optimizer_kwargs)\n",
    "\n",
    "trainh_config = {\n",
    "    'early_stop_epochcheck_epochs':1, # every n epochs check\n",
    "    #'early_stop_epochcheck_epochs':2, # every n epochs check\n",
    "    'early_stop_patience_epochchecks':int(1e2),\n",
    "    #'save_mode':_C.SM_NO_SAVE,\n",
    "    #'save_mode':_C.SM_ALL,\n",
    "    #'save_mode':_C.SM_ONLY_ALL,\n",
    "    #'save_mode':_C.SM_ONLY_INF_METRIC,\n",
    "    #'save_mode':_C.SM_ONLY_INF_LOSS,\n",
    "    'save_mode':_C.SM_ONLY_SUP_METRIC,\n",
    "}\n",
    "model1 = mdl_params['mdl_class'](**mdl_params['mdl_kwargs'])\n",
    "#assert 0\n",
    "#model2 = SimpleClassifier()\n",
    "train_handlers = [\n",
    "    NewTrainHandler('crossentropy', model1, optimizer1, loss_crit1, metric_crits, **trainh_config),\n",
    "    #NewTrainHandler('lower-bound', model2, optimizer2, loss_crit2, metric_crits, **trainh_config),\n",
    "]\n",
    "#train_handlers = NewTrainHandler('crossentropy', model, optimizer1, loss_crit, metric_crits, **train_config)\n",
    "\n",
    "mtrain_config = {\n",
    "    'id':0,\n",
    "    'epochs_max':int(1e3),\n",
    "    'save_dir':'save',\n",
    "}\n",
    "model_name = model1.get_name()\n",
    "train_handler = ModelsTrainHandler(model_name, train_handlers, **mtrain_config)\n",
    "train_handler.build(gpu_index=0)\n",
    "train_handler.fit_loader(train_loader_mnist, val_loader_mnist, load=LOAD) # FIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import flamingChoripan.tinyFlame.plots as tfplots\n",
    "\n",
    "### training plots\n",
    "fig, ax = tfplots.plot_trainloss(train_handler)\n",
    "fig, ax = tfplots.plot_evaluation_loss(train_handler)\n",
    "fig, ax = tfplots.plot_evaluation_metrics(train_handler)\n",
    "#fig, ax = tfplots.plot_optimizer(train_handler, save_dir=mtrain_config['images_save_dir'])\n",
    "plt.show()\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# prediction and CM"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
