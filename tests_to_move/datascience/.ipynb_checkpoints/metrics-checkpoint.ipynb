{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../../') # or just install the module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# https://blog.finxter.com/how-to-plot-sklearn-confusion-matrix-with-labels/\n",
    "actual_data = \\\n",
    "       ['apples',  'pears',   'apples',\n",
    "        'apples',  'apples',  'pears',\n",
    "        'oranges', 'oranges', 'apples',\n",
    "        'apples',  'apples',  'apples',\n",
    "        'apples',  'apples',  'pears',\n",
    "        'apples',  'oranges', 'apples',\n",
    "        'apples',  'apples']\n",
    "predicted_data = \\\n",
    "      ['oranges', 'pears',   'apples',\n",
    "       'apples',  'apples',  'pears',\n",
    "       'oranges', 'oranges', 'apples', \n",
    "       'apples',  'apples',  'apples',\n",
    "       'apples',  'apples',  'pears',\n",
    "       'apples',  'oranges', 'oranges',\n",
    "       'apples',  'oranges']\n",
    "\n",
    "class_names = np.unique(actual_data)\n",
    "d = {c:kc for kc,c in enumerate(class_names)}\n",
    "print(d)\n",
    "y_pred_p = []\n",
    "y_true = []\n",
    "for k in range(0, len(actual_data)):\n",
    "    y_true += [d[actual_data[k]]]\n",
    "    _p = .8\n",
    "    p = np.zeros(shape=(len(class_names)))+(1-_p)/(len(class_names)-1)\n",
    "    p[d[predicted_data[k]]] = _p\n",
    "    y_pred_p += [p]\n",
    "y_pred_p = np.array(y_pred_p)\n",
    "y_true = np.array(y_true)\n",
    "print(y_pred_p, y_pred_p.shape, y_true, class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from fuzzytools.datascience import metrics\n",
    "from fuzzytools.datascience.cms import ConfusionMatrix\n",
    "from fuzzytools.matplotlib.cm_plots import plot_custom_confusion_matrix\n",
    "import pandas as pd\n",
    "\n",
    "metrics_cdict, metrics_dict, cm = metrics.get_multiclass_metrics(y_pred_p, y_true, class_names)\n",
    "title = ''\n",
    "print(cm)\n",
    "cm = ConfusionMatrix([cm, cm+.1], class_names)\n",
    "cm.reorder_classes(['oranges', 'pears', 'apples'])\n",
    "display(cm)\n",
    "true_label_d = {c:'e' for c in class_names}\n",
    "plot_custom_confusion_matrix(cm,\n",
    "    title=title[:-1],\n",
    "    figsize=(6,5),\n",
    "    true_label_d=true_label_d,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "cm2 = (cm+cm+cm)/1\n",
    "display(cm2)\n",
    "cm2 = sum([cm,cm,cm])/1\n",
    "display(cm2)\n",
    "plot_custom_confusion_matrix(cm2,\n",
    "    title=title[:-1],\n",
    "    figsize=(6,5),\n",
    "    true_label_d=true_label_d,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from fuzzytools.datascience import metrics as metrics\n",
    "from fuzzytools.matplotlib.cm_plots import plot_custom_confusion_matrix\n",
    "\n",
    "metrics_cdict, metrics_dict, cm = metrics.get_multiclass_metrics(y_pred_p, y_target, class_names)\n",
    "print(metrics_cdict[class_names[0]].keys())\n",
    "print(metrics_dict.keys())\n",
    "{c:metrics_cdict[c]['recall'] for c in class_names}\n",
    "for k in metrics_dict.keys():\n",
    "    if 'w-' in k:\n",
    "        continue\n",
    "    print(k, metrics_dict[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics as skmetrics\n",
    "\n",
    "precision, recall, f1score,_ = skmetrics.precision_recall_fscore_support(y_target, y_pred_p.argmax(axis=-1),\n",
    "                average=None,\n",
    "                labels=range(0, len(class_names)),\n",
    "                )\n",
    "print(np.mean(precision))\n",
    "print(np.mean(recall))\n",
    "print(np.mean(f1score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision, recall, score,_ = skmetrics.precision_recall_fscore_support(\n",
    "    np.array([0, 0, 0 ,1 ,0 ,1, 0, 0 ,0, 1, 0, 0, 1, 0, 0, 1 ,0, 0 ,0 ,1]).astype(bool),\n",
    "    np.array([0 ,0, 1, 0 ,0, 1 ,1 ,0, 0, 0, 0, 1, 0, 0, 0, 0, 0 ,0, 0 ,0]).astype(bool),\n",
    "    average='binary', pos_label=1)\n",
    "print(precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "rocc = metrics_cdict['a']['rocc']\n",
    "plt.plot(rocc['fpr'], rocc['tpr'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "rocc = metrics_cdict['a']['prc']\n",
    "plt.plot(rocc['recall'], rocc['precision'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
